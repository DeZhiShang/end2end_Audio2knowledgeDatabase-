"""
éŸ³é¢‘åˆ‡åˆ†æ¨¡å—
è´Ÿè´£æ ¹æ®RTTMæ–‡ä»¶åˆ‡åˆ†éŸ³é¢‘
"""

import warnings
# è¿‡æ»¤ç›¸å…³è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning)

import torchaudio
import os
from tqdm import tqdm


class AudioSegmentation:
    """éŸ³é¢‘åˆ‡åˆ†å¤„ç†å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–éŸ³é¢‘åˆ‡åˆ†å™¨"""
        pass

    def parse_rttm_and_segment(self, rttm_file, wav_file, output_dir):
        """
        è§£æRTTMæ–‡ä»¶å¹¶æ ¹æ®æ—¶é—´æˆ³åˆ‡åˆ†éŸ³é¢‘

        Args:
            rttm_file: RTTMæ–‡ä»¶è·¯å¾„
            wav_file: åŸå§‹WAVéŸ³é¢‘æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„
        """
        # åŠ è½½åŸå§‹éŸ³é¢‘
        waveform, sample_rate = torchaudio.load(wav_file)

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)

        # è¯»å–å¹¶è§£æRTTMæ–‡ä»¶å†…å®¹
        segments = []
        with open(rttm_file, 'r') as f:
            for line in f:
                line = line.strip()
                if line:
                    parts = line.split()
                    if len(parts) >= 8:
                        start_time = float(parts[3])  # ç¬¬4åˆ—ï¼šèµ·å§‹æ—¶é—´
                        duration = float(parts[4])    # ç¬¬5åˆ—ï¼šæŒç»­æ—¶é—´
                        speaker_id = parts[7]         # ç¬¬8åˆ—ï¼šè¯´è¯äººID

                        segments.append({
                            'start_time': start_time,
                            'duration': duration,
                            'speaker_id': speaker_id,
                            'end_time': start_time + duration
                        })

        # æŒ‰èµ·å§‹æ—¶é—´æ’åºï¼Œç¡®ä¿å¤„ç†é¡ºåºæ­£ç¡®
        segments.sort(key=lambda x: x['start_time'])
        print(f"ğŸ“Š è¯»å–åˆ° {len(segments)} ä¸ªéŸ³é¢‘ç‰‡æ®µï¼ŒæŒ‰èµ·å§‹æ—¶é—´æ’åº")

        # ä½¿ç”¨tqdmæ˜¾ç¤ºéŸ³é¢‘åˆ‡åˆ†è¿›åº¦
        segment_count = 0
        with tqdm(segments, desc="âœ‚ï¸ åˆ‡åˆ†éŸ³é¢‘ç‰‡æ®µ", unit="ç‰‡æ®µ") as pbar:
            for seg in pbar:
                start_time = seg['start_time']
                duration = seg['duration']
                speaker_id = seg['speaker_id']
                end_time = seg['end_time']

                # éªŒè¯æ—¶é—´é€»è¾‘
                if duration <= 0:
                    print(f"âš ï¸ è·³è¿‡æ— æ•ˆæ—¶é•¿ç‰‡æ®µ: {start_time:.3f}s, æ—¶é•¿={duration:.3f}s")
                    continue

                # è®¡ç®—æ ·æœ¬ç´¢å¼•
                start_sample = int(start_time * sample_rate)
                end_sample = int(end_time * sample_rate)

                # ç¡®ä¿ä¸è¶…å‡ºéŸ³é¢‘é•¿åº¦
                if start_sample >= waveform.shape[1]:
                    print(f"âš ï¸ è·³è¿‡è¶…å‡ºéŸ³é¢‘é•¿åº¦çš„ç‰‡æ®µ: {start_time:.3f}s")
                    continue

                if end_sample > waveform.shape[1]:
                    end_sample = waveform.shape[1]
                    end_time = end_sample / sample_rate

                # ç¡®ä¿èµ·å§‹æ ·æœ¬å°äºç»“æŸæ ·æœ¬
                if start_sample >= end_sample:
                    print(f"âš ï¸ è·³è¿‡æ— æ•ˆæ ·æœ¬èŒƒå›´: start={start_sample}, end={end_sample}")
                    continue

                # åˆ‡åˆ†éŸ³é¢‘ç‰‡æ®µ
                segment = waveform[:, start_sample:end_sample]

                # ç”Ÿæˆæ–‡ä»¶åï¼šè¯´è¯äºº-èµ·å§‹æ—¶é—´-ç»“æŸæ—¶é—´.wav (ä½¿ç”¨åºå·ç¡®ä¿æœ‰åº)
                filename = f"{segment_count:03d}_{speaker_id}-{start_time:.3f}-{end_time:.3f}.wav"
                output_path = os.path.join(output_dir, filename)

                # ä¿å­˜éŸ³é¢‘ç‰‡æ®µ
                torchaudio.save(output_path, segment, sample_rate)
                segment_count += 1

                # æ›´æ–°è¿›åº¦æ¡ä¿¡æ¯
                pbar.set_postfix(
                    speaker=speaker_id,
                    start=f"{start_time:.2f}s",
                    duration=f"{duration:.2f}s",
                    refresh=True
                )

        print(f"æˆåŠŸåˆ‡åˆ† {segment_count} ä¸ªéŸ³é¢‘ç‰‡æ®µ")