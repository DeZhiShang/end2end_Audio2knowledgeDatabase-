"""
çŸ¥è¯†åº“é›†æˆæ¨¡å—
å°†é—®ç­”å¯¹æŠ½å–é›†æˆåˆ°ç°æœ‰éŸ³é¢‘å¤„ç†æµç¨‹ä¸­
"""

import os
from typing import Dict, Any, Optional
from datetime import datetime
import threading

from src.utils.logger import get_logger
from src.core.knowledge_base import get_knowledge_base, ProcessingStatus
from src.core.qa_extractor import QAExtractor
from src.core.qa_compactor import get_qa_compactor, CompactionScheduler
from src.core.system_monitor import get_system_monitor, cleanup_system_monitor
from src.utils.concurrency import get_concurrency_monitor, thread_safe_operation


class KnowledgeProcessor:
    """çŸ¥è¯†å¤„ç†å™¨ - ç®¡ç†é—®ç­”å¯¹æŠ½å–å’ŒçŸ¥è¯†åº“é›†æˆ"""

    def __init__(self, enable_auto_qa_extraction: bool = True, enable_auto_compaction: bool = True, enable_system_monitoring: bool = True, enable_auto_cleanup: bool = True, cleanup_dry_run: bool = False):
        """
        åˆå§‹åŒ–çŸ¥è¯†å¤„ç†å™¨

        Args:
            enable_auto_qa_extraction: æ˜¯å¦å¯ç”¨è‡ªåŠ¨é—®ç­”å¯¹æŠ½å–
            enable_auto_compaction: æ˜¯å¦å¯ç”¨è‡ªåŠ¨å‹ç¼©
            enable_system_monitoring: æ˜¯å¦å¯ç”¨ç³»ç»Ÿç›‘æ§
            enable_auto_cleanup: æ˜¯å¦å¯ç”¨è‡ªåŠ¨æ¸…ç†ä¸­é—´æ–‡ä»¶
            cleanup_dry_run: æ˜¯å¦ä¸ºæ¸…ç†å¹²è¿è¡Œæ¨¡å¼
        """
        self.logger = get_logger(__name__)
        self.enable_auto_qa_extraction = enable_auto_qa_extraction
        self.enable_auto_compaction = enable_auto_compaction
        self.enable_system_monitoring = enable_system_monitoring
        self.enable_auto_cleanup = enable_auto_cleanup
        self.cleanup_dry_run = cleanup_dry_run

        # æ ¸å¿ƒç»„ä»¶
        self.knowledge_base = get_knowledge_base()
        self.qa_extractor = None  # å»¶è¿Ÿåˆå§‹åŒ–
        self.qa_compactor = None  # å»¶è¿Ÿåˆå§‹åŒ–
        self.compaction_scheduler = None  # å»¶è¿Ÿåˆå§‹åŒ–
        self.system_monitor = None  # å»¶è¿Ÿåˆå§‹åŒ–

        # å¹¶å‘ç›‘æ§
        self.concurrency_monitor = get_concurrency_monitor()

        # å¤„ç†ç»Ÿè®¡
        self.processing_stats = {
            'total_files_processed': 0,
            'qa_extraction_success': 0,
            'qa_extraction_failed': 0,
            'total_qa_pairs_extracted': 0,
            'last_processing_time': None
        }

        # åˆå§‹åŒ–ç³»ç»Ÿç›‘æ§
        if self.enable_system_monitoring:
            self.system_monitor = get_system_monitor()
            self.system_monitor.start_monitoring()
            self.logger.info("ç³»ç»Ÿç›‘æ§å·²å¯åŠ¨")

        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç«‹å³åˆå§‹åŒ–å‹ç¼©å™¨
        if self.enable_auto_compaction:
            self._check_and_initialize_compactor()

        self.logger.info(f"çŸ¥è¯†å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ - QAæŠ½å–: {enable_auto_qa_extraction}, è‡ªåŠ¨å‹ç¼©: {enable_auto_compaction}, ç³»ç»Ÿç›‘æ§: {enable_system_monitoring}, æ–‡ä»¶æ¸…ç†: {enable_auto_cleanup}")

    def _initialize_qa_extractor(self):
        """å»¶è¿Ÿåˆå§‹åŒ–é—®ç­”å¯¹æŠ½å–å™¨"""
        if self.qa_extractor is None:
            try:
                self.qa_extractor = QAExtractor(
                    enable_auto_cleanup=self.enable_auto_cleanup,
                    cleanup_dry_run=self.cleanup_dry_run
                )
                cleanup_mode = "å¹²è¿è¡Œæ¨¡å¼" if self.cleanup_dry_run else "å®é™…åˆ é™¤æ¨¡å¼"
                self.logger.info(f"é—®ç­”å¯¹æŠ½å–å™¨åˆå§‹åŒ–æˆåŠŸ (æ–‡ä»¶æ¸…ç†: {'å¯ç”¨' if self.enable_auto_cleanup else 'ç¦ç”¨'}, {cleanup_mode if self.enable_auto_cleanup else ''})")
            except Exception as e:
                self.logger.warning(f"é—®ç­”å¯¹æŠ½å–å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                self.qa_extractor = False  # æ ‡è®°ä¸ºå¤±è´¥

    def _check_and_initialize_compactor(self):
        """æ£€æŸ¥çŸ¥è¯†åº“å¤§å°å¹¶åœ¨éœ€è¦æ—¶åˆå§‹åŒ–å‹ç¼©å™¨"""
        if not self.enable_auto_compaction:
            return

        try:
            kb_stats = self.knowledge_base.get_statistics()
            total_qa_pairs = kb_stats.get('total_qa_pairs', 0)

            # å¦‚æœé—®ç­”å¯¹æ•°é‡è¶…è¿‡é˜ˆå€¼ä¸”å‹ç¼©å™¨æœªåˆå§‹åŒ–ï¼Œåˆ™ç«‹å³åˆå§‹åŒ–
            if total_qa_pairs >= 50 and self.qa_compactor is None:
                self.logger.info(f"çŸ¥è¯†åº“é—®ç­”å¯¹æ•°é‡({total_qa_pairs})å·²è¶…è¿‡é˜ˆå€¼ï¼Œå¯åŠ¨å‹ç¼©å™¨")
                self._initialize_qa_compactor()
            elif total_qa_pairs < 50:
                self.logger.debug(f"çŸ¥è¯†åº“é—®ç­”å¯¹æ•°é‡({total_qa_pairs})æœªè¾¾åˆ°å‹ç¼©é˜ˆå€¼(50)")

        except Exception as e:
            self.logger.warning(f"æ£€æŸ¥å‹ç¼©å™¨åˆå§‹åŒ–æ¡ä»¶å¤±è´¥: {str(e)}")

    def _initialize_qa_compactor(self):
        """å»¶è¿Ÿåˆå§‹åŒ–é—®ç­”å¯¹å‹ç¼©å™¨"""
        if self.qa_compactor is None:
            try:
                self.qa_compactor = get_qa_compactor()
                self.logger.info("é—®ç­”å¯¹å‹ç¼©å™¨åˆå§‹åŒ–æˆåŠŸ")

                # å¯åŠ¨å‹ç¼©è°ƒåº¦å™¨
                if self.enable_auto_compaction:
                    self.compaction_scheduler = CompactionScheduler(self.qa_compactor, interval_minutes=1)
                    self.compaction_scheduler.start_scheduler()
                    self.logger.info("è‡ªåŠ¨å‹ç¼©è°ƒåº¦å™¨å¯åŠ¨æˆåŠŸ")

            except Exception as e:
                self.logger.warning(f"é—®ç­”å¯¹å‹ç¼©å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                self.qa_compactor = False  # æ ‡è®°ä¸ºå¤±è´¥

    @thread_safe_operation("process_cleaned_file")
    def process_cleaned_file(self, file_path: str, force_extraction: bool = False) -> Dict[str, Any]:
        """
        å¤„ç†å·²æ¸…æ´—çš„æ–‡ä»¶ï¼Œæ‰§è¡Œé—®ç­”å¯¹æŠ½å–

        Args:
            file_path: å·²æ¸…æ´—çš„æ–‡ä»¶è·¯å¾„
            force_extraction: æ˜¯å¦å¼ºåˆ¶é‡æ–°æŠ½å–

        Returns:
            Dict[str, Any]: å¤„ç†ç»“æœ
        """
        if not self.enable_auto_qa_extraction:
            return {
                "success": False,
                "message": "è‡ªåŠ¨é—®ç­”å¯¹æŠ½å–å·²ç¦ç”¨"
            }

        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(file_path):
                return {
                    "success": False,
                    "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
                }

            # æ£€æŸ¥æ–‡ä»¶çŠ¶æ€
            file_status = self.knowledge_base.get_file_status(file_path)
            if not force_extraction and file_status and file_status.status in [
                ProcessingStatus.QA_EXTRACTED, ProcessingStatus.COMPACTED
            ]:
                self.logger.info(f"æ–‡ä»¶å·²å¤„ç†ï¼Œè·³è¿‡: {file_path} (çŠ¶æ€: {file_status.status.value})")
                return {
                    "success": True,
                    "message": "æ–‡ä»¶å·²å¤„ç†ï¼Œè·³è¿‡",
                    "file_path": file_path,
                    "status": file_status.status.value
                }

            # æ›´æ–°æ–‡ä»¶çŠ¶æ€ä¸ºæ¸…æ´—å®Œæˆ
            self.knowledge_base.update_file_status(
                file_path,
                ProcessingStatus.CLEAN_FINISHED,
                {"clean_finished_time": datetime.now().isoformat()}
            )

            # åˆå§‹åŒ–é—®ç­”å¯¹æŠ½å–å™¨
            self._initialize_qa_extractor()
            if not self.qa_extractor or self.qa_extractor is False:
                return {
                    "success": False,
                    "error": "é—®ç­”å¯¹æŠ½å–å™¨ä¸å¯ç”¨",
                    "file_path": file_path
                }

            # æ‰§è¡Œé—®ç­”å¯¹æŠ½å–
            self.logger.info(f"å¼€å§‹æŠ½å–æ–‡ä»¶: {os.path.basename(file_path)}")
            extraction_result = self.qa_extractor.extract_and_save_qa_pairs(file_path)

            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.processing_stats['total_files_processed'] += 1
            self.processing_stats['last_processing_time'] = datetime.now().isoformat()

            if extraction_result["success"]:
                qa_count = extraction_result.get("qa_count", 0)
                self.processing_stats['qa_extraction_success'] += 1
                self.processing_stats['total_qa_pairs_extracted'] += qa_count

                self.logger.info(f"âœ… æ–‡ä»¶æŠ½å–æˆåŠŸ: {os.path.basename(file_path)}, æŠ½å– {qa_count} ä¸ªé—®ç­”å¯¹")

                # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆå§‹åŒ–å‹ç¼©å™¨
                if self.enable_auto_compaction and self.qa_compactor is None:
                    self._check_and_initialize_compactor()

                return {
                    "success": True,
                    "file_path": file_path,
                    "qa_count": qa_count,
                    "summary": extraction_result.get("summary", {}),
                    "token_usage": extraction_result.get("token_usage", {})
                }
            else:
                self.processing_stats['qa_extraction_failed'] += 1
                error_msg = extraction_result.get("error", "æœªçŸ¥é”™è¯¯")

                self.logger.error(f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {os.path.basename(file_path)}, é”™è¯¯: {error_msg}")

                return {
                    "success": False,
                    "error": error_msg,
                    "file_path": file_path
                }

        except Exception as e:
            self.processing_stats['qa_extraction_failed'] += 1
            self.logger.error(f"å¤„ç†æ–‡ä»¶å¼‚å¸¸: {file_path}, é”™è¯¯: {str(e)}")

            return {
                "success": False,
                "error": str(e),
                "file_path": file_path
            }

    @thread_safe_operation("batch_process_cleaned_files")
    def batch_process_cleaned_files(self) -> Dict[str, Any]:
        """
        æ‰¹é‡å¤„ç†æ‰€æœ‰å·²æ¸…æ´—çš„æ–‡ä»¶

        Returns:
            Dict[str, Any]: æ‰¹é‡å¤„ç†ç»“æœ
        """
        if not self.enable_auto_qa_extraction:
            return {
                "success": False,
                "message": "è‡ªåŠ¨é—®ç­”å¯¹æŠ½å–å·²ç¦ç”¨"
            }

        try:
            # è·å–æ‰€æœ‰æ¸…æ´—å®Œæˆä½†æœªæŠ½å–é—®ç­”å¯¹çš„æ–‡ä»¶
            clean_finished_files = self.knowledge_base.get_clean_finished_files()

            if not clean_finished_files:
                self.logger.info("æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤„ç†çš„æ–‡ä»¶")
                return {
                    "success": True,
                    "message": "æ²¡æœ‰éœ€è¦å¤„ç†çš„æ–‡ä»¶",
                    "processed_files": 0
                }

            self.logger.info(f"å¼€å§‹æ‰¹é‡å¤„ç† {len(clean_finished_files)} ä¸ªæ–‡ä»¶")

            results = []
            success_count = 0
            error_count = 0

            for file_path in clean_finished_files:
                result = self.process_cleaned_file(file_path)
                results.append(result)

                if result["success"]:
                    success_count += 1
                else:
                    error_count += 1

            self.logger.info(f"æ‰¹é‡å¤„ç†å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {error_count}")

            return {
                "success": True,
                "total_files": len(clean_finished_files),
                "success_count": success_count,
                "error_count": error_count,
                "results": results,
                "processing_stats": self.processing_stats.copy()
            }

        except Exception as e:
            self.logger.error(f"æ‰¹é‡å¤„ç†å¼‚å¸¸: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }

    @thread_safe_operation("trigger_compaction")
    def trigger_compaction(self, similarity_threshold: float = None) -> Dict[str, Any]:
        """
        æ‰‹åŠ¨è§¦å‘å‹ç¼©æ“ä½œ

        Args:
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼

        Returns:
            Dict[str, Any]: å‹ç¼©ç»“æœ
        """
        try:
            # ä»é…ç½®è·å–é»˜è®¤ç›¸ä¼¼æ€§é˜ˆå€¼
            if similarity_threshold is None:
                try:
                    from config import get_config
                    similarity_threshold = get_config('system.compaction.knowledge_integration.qa_similarity_threshold', 0.75)
                except Exception:
                    similarity_threshold = 0.75

            # åˆå§‹åŒ–å‹ç¼©å™¨
            self._initialize_qa_compactor()
            if not self.qa_compactor or self.qa_compactor is False:
                return {
                    "success": False,
                    "error": "é—®ç­”å¯¹å‹ç¼©å™¨ä¸å¯ç”¨"
                }

            # è·å–å½“å‰çš„é—®ç­”å¯¹æ•°æ®
            all_qa_pairs = self.knowledge_base.get_all_qa_pairs()

            if len(all_qa_pairs) < 10:  # è‡³å°‘éœ€è¦10ä¸ªé—®ç­”å¯¹æ‰æœ‰å‹ç¼©æ„ä¹‰
                return {
                    "success": False,
                    "message": f"é—®ç­”å¯¹æ•°é‡ä¸è¶³ï¼Œæ— éœ€å‹ç¼© (å½“å‰: {len(all_qa_pairs)})"
                }

            self.logger.info(f"å¼€å§‹å‹ç¼© {len(all_qa_pairs)} ä¸ªé—®ç­”å¯¹...")

            # åˆ›å»ºå¿«ç…§
            snapshot = self.knowledge_base.create_snapshot()
            if not snapshot:
                return {
                    "success": False,
                    "error": "åˆ›å»ºå¿«ç…§å¤±è´¥"
                }

            # æ‰§è¡Œå‹ç¼©ï¼ˆé»˜è®¤ä½¿ç”¨LLMæ™ºèƒ½æ£€éªŒï¼‰
            compaction_result = self.qa_compactor.compact_qa_pairs(
                snapshot.data, similarity_threshold, use_llm_similarity=True
            )

            if compaction_result["success"]:
                # åˆ‡æ¢ç¼“å†²åŒºå¹¶åŒæ­¥å°¾éƒ¨æ•°æ®
                compacted_qa_pairs = compaction_result["compacted_qa_pairs"]
                switch_success = self.knowledge_base.switch_buffers_with_tail_sync(compacted_qa_pairs)

                if switch_success:
                    self.logger.info(f"âœ… å‹ç¼©å®Œæˆ: {compaction_result['compression_ratio']:.2%} å‹ç¼©ç‡")

                    return {
                        "success": True,
                        "original_count": compaction_result["original_count"],
                        "final_count": compaction_result["final_count"],
                        "compression_ratio": compaction_result["compression_ratio"],
                        "processing_time": compaction_result["processing_time"]
                    }
                else:
                    return {
                        "success": False,
                        "error": "ç¼“å†²åŒºåˆ‡æ¢å¤±è´¥"
                    }
            else:
                return {
                    "success": False,
                    "error": compaction_result.get("error", "å‹ç¼©å¤±è´¥")
                }

        except Exception as e:
            self.logger.error(f"å‹ç¼©æ“ä½œå¼‚å¸¸: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }

    def get_knowledge_base_status(self) -> Dict[str, Any]:
        """
        è·å–çŸ¥è¯†åº“çŠ¶æ€

        Returns:
            Dict[str, Any]: çŸ¥è¯†åº“çŠ¶æ€ä¿¡æ¯
        """
        try:
            # çŸ¥è¯†åº“ç»Ÿè®¡
            kb_stats = self.knowledge_base.get_statistics()

            # å¤„ç†ç»Ÿè®¡
            processing_stats = self.processing_stats.copy()

            # å¹¶å‘ç»Ÿè®¡
            concurrency_stats = self.concurrency_monitor.get_statistics()

            # å‹ç¼©ç»Ÿè®¡
            compaction_stats = {}
            scheduler_stats = {}
            if self.qa_compactor and self.qa_compactor is not False:
                compaction_stats = self.qa_compactor.get_compaction_statistics()
            if self.compaction_scheduler:
                scheduler_stats = self.compaction_scheduler.get_scheduler_statistics()

            # ç³»ç»Ÿç›‘æ§ç»Ÿè®¡
            system_monitor_stats = {}
            if self.system_monitor:
                system_monitor_stats = self.system_monitor.get_system_status()

            return {
                "knowledge_base": kb_stats,
                "processing": processing_stats,
                "concurrency": concurrency_stats,
                "compaction": compaction_stats,
                "scheduler": scheduler_stats,
                "system_monitor": system_monitor_stats,
                "auto_qa_extraction": self.enable_auto_qa_extraction,
                "auto_compaction": self.enable_auto_compaction,
                "system_monitoring": self.enable_system_monitoring,
                "components_status": {
                    "qa_extractor": self.qa_extractor is not None and self.qa_extractor is not False,
                    "qa_compactor": self.qa_compactor is not None and self.qa_compactor is not False,
                    "compaction_scheduler": self.compaction_scheduler is not None and self.compaction_scheduler.is_running,
                    "system_monitor": self.system_monitor is not None and self.system_monitor.is_monitoring
                }
            }

        except Exception as e:
            self.logger.error(f"è·å–çŸ¥è¯†åº“çŠ¶æ€å¤±è´¥: {str(e)}")
            return {
                "error": str(e),
                "components_status": {
                    "qa_extractor": False,
                    "qa_compactor": False,
                    "compaction_scheduler": False
                }
            }

    def _perform_final_compaction(self) -> Dict[str, Any]:
        """
        æ‰§è¡Œæœ€ç»ˆå‹ç¼©æ“ä½œ
        åœ¨ç³»ç»Ÿå…³é—­å‰ç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½ç»è¿‡å‹ç¼©ä¼˜åŒ–

        Returns:
            Dict[str, Any]: å‹ç¼©ç»“æœ
        """
        try:
            self.logger.info("ğŸ”„ å¼€å§‹æ‰§è¡Œæœ€ç»ˆå‹ç¼©æ£€æŸ¥...")

            # åˆå§‹åŒ–å‹ç¼©å™¨ï¼ˆå¦‚æœå°šæœªåˆå§‹åŒ–ï¼‰
            self._initialize_qa_compactor()
            if not self.qa_compactor or self.qa_compactor is False:
                self.logger.info("å‹ç¼©å™¨ä¸å¯ç”¨ï¼Œè·³è¿‡æœ€ç»ˆå‹ç¼©")
                return {
                    "success": False,
                    "reason": "compactor_unavailable",
                    "message": "å‹ç¼©å™¨ä¸å¯ç”¨"
                }

            # è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯
            kb_stats = self.knowledge_base.get_statistics()
            total_qa_pairs = kb_stats.get('total_qa_pairs', 0)
            active_buffer_size = kb_stats.get('active_buffer_size', 0)

            self.logger.info(f"çŸ¥è¯†åº“çŠ¶æ€: æ€»è®¡{total_qa_pairs}ä¸ªé—®ç­”å¯¹, æ´»è·ƒç¼“å†²åŒº{active_buffer_size}ä¸ª")

            # ä½¿ç”¨æ›´å®½æ¾çš„æœ€ç»ˆå‹ç¼©æ¡ä»¶ - ä»é…ç½®ç³»ç»Ÿè·å–
            try:
                from config import get_config
                final_compression_threshold = get_config('system.compaction.knowledge_integration.final_compression_threshold', 5)
            except Exception:
                final_compression_threshold = 5  # æœ€ç»ˆå‹ç¼©çš„æœ€å°é˜ˆå€¼

            if total_qa_pairs < final_compression_threshold:
                self.logger.info(f"é—®ç­”å¯¹æ•°é‡ä¸è¶³({total_qa_pairs} < {final_compression_threshold})ï¼Œè·³è¿‡æœ€ç»ˆå‹ç¼©")
                return {
                    "success": False,
                    "reason": "insufficient_data",
                    "message": f"é—®ç­”å¯¹æ•°é‡ä¸è¶³: {total_qa_pairs}"
                }

            # æ£€æŸ¥æ´»è·ƒç¼“å†²åŒºæ˜¯å¦æœ‰æ•°æ®éœ€è¦å‹ç¼©
            if active_buffer_size == 0:
                self.logger.info("æ´»è·ƒç¼“å†²åŒºä¸ºç©ºï¼Œæ— éœ€æœ€ç»ˆå‹ç¼©")
                return {
                    "success": False,
                    "reason": "no_active_data",
                    "message": "æ´»è·ƒç¼“å†²åŒºä¸ºç©º"
                }

            self.logger.info(f"âœ… æ»¡è¶³æœ€ç»ˆå‹ç¼©æ¡ä»¶ï¼Œå¼€å§‹å‹ç¼© {total_qa_pairs} ä¸ªé—®ç­”å¯¹...")

            # åˆ›å»ºå¿«ç…§
            snapshot = self.knowledge_base.create_snapshot()
            if not snapshot:
                self.logger.error("åˆ›å»ºå¿«ç…§å¤±è´¥ï¼Œæœ€ç»ˆå‹ç¼©ä¸­æ­¢")
                return {
                    "success": False,
                    "reason": "snapshot_failed",
                    "error": "åˆ›å»ºå¿«ç…§å¤±è´¥"
                }

            # æ‰§è¡Œå‹ç¼©ï¼ˆä½¿ç”¨LLMæ™ºèƒ½æ£€éªŒï¼Œé€‚ä¸­çš„ç›¸ä¼¼åº¦é˜ˆå€¼ï¼‰
            self.logger.info("æ­£åœ¨æ‰§è¡Œæœ€ç»ˆå‹ç¼©...")

            # ä»é…ç½®è·å–æœ€ç»ˆå‹ç¼©ç›¸ä¼¼åº¦é˜ˆå€¼
            try:
                from config import get_config
                final_threshold = get_config('system.similarity.thresholds.final_compression', 0.7)
            except Exception:
                final_threshold = 0.7

            compaction_result = self.qa_compactor.compact_qa_pairs(
                snapshot.data,
                similarity_threshold=final_threshold,  # ç¨å¾®å®½æ¾çš„é˜ˆå€¼ï¼Œç¡®ä¿æ›´å¥½çš„å‹ç¼©æ•ˆæœ
                use_llm_similarity=True
            )

            if compaction_result["success"]:
                # åˆ‡æ¢ç¼“å†²åŒºå¹¶åŒæ­¥å°¾éƒ¨æ•°æ®
                compacted_qa_pairs = compaction_result["compacted_qa_pairs"]
                switch_success = self.knowledge_base.switch_buffers_with_tail_sync(compacted_qa_pairs)

                if switch_success:
                    compression_ratio = compaction_result["compression_ratio"]
                    original_count = compaction_result["original_count"]
                    final_count = compaction_result["final_count"]

                    self.logger.info(f"ğŸ‰ æœ€ç»ˆå‹ç¼©å®Œæˆï¼")
                    self.logger.info(f"ğŸ“Š å‹ç¼©ç»Ÿè®¡: {original_count} â†’ {final_count} ({compression_ratio:.2%} å‹ç¼©ç‡)")

                    return {
                        "success": True,
                        "original_count": original_count,
                        "final_count": final_count,
                        "compression_ratio": compression_ratio,
                        "processing_time": compaction_result["processing_time"]
                    }
                else:
                    self.logger.error("æœ€ç»ˆå‹ç¼©çš„ç¼“å†²åŒºåˆ‡æ¢å¤±è´¥")
                    return {
                        "success": False,
                        "reason": "buffer_switch_failed",
                        "error": "ç¼“å†²åŒºåˆ‡æ¢å¤±è´¥"
                    }
            else:
                error_msg = compaction_result.get("error", "æœªçŸ¥å‹ç¼©é”™è¯¯")
                self.logger.warning(f"æœ€ç»ˆå‹ç¼©å¤±è´¥: {error_msg}")
                return {
                    "success": False,
                    "reason": "compression_failed",
                    "error": error_msg
                }

        except Exception as e:
            self.logger.error(f"æœ€ç»ˆå‹ç¼©è¿‡ç¨‹å¼‚å¸¸: {str(e)}")
            return {
                "success": False,
                "reason": "exception",
                "error": str(e)
            }

    def shutdown(self):
        """å…³é—­çŸ¥è¯†å¤„ç†å™¨ï¼Œæ¸…ç†èµ„æº"""
        try:
            # æ‰§è¡Œæœ€ç»ˆå‹ç¼©ï¼ˆåœ¨åœæ­¢è°ƒåº¦å™¨ä¹‹å‰ï¼‰
            if self.enable_auto_compaction:
                self.logger.info("=" * 60)
                self.logger.info("ğŸ”„ æ‰§è¡Œæœ€ç»ˆå‹ç¼©æµç¨‹")
                self.logger.info("=" * 60)

                final_compression_result = self._perform_final_compaction()

                if final_compression_result["success"]:
                    self.logger.info("âœ… æœ€ç»ˆå‹ç¼©æˆåŠŸå®Œæˆ")
                else:
                    reason = final_compression_result.get("reason", "unknown")
                    if reason in ["insufficient_data", "no_active_data", "compactor_unavailable"]:
                        self.logger.info(f"â„¹ï¸ è·³è¿‡æœ€ç»ˆå‹ç¼©: {final_compression_result.get('message', reason)}")
                    else:
                        self.logger.warning(f"âš ï¸ æœ€ç»ˆå‹ç¼©æœªæˆåŠŸ: {final_compression_result.get('error', reason)}")
                        self.logger.info("æ•°æ®å°†æ­£å¸¸ä¿å­˜ï¼Œä¸å—å‹ç¼©å½±å“")

            # åœæ­¢å‹ç¼©è°ƒåº¦å™¨
            if self.compaction_scheduler:
                self.logger.info("åœæ­¢å‹ç¼©è°ƒåº¦å™¨...")
                self.compaction_scheduler.stop_scheduler()

            # åœæ­¢ç³»ç»Ÿç›‘æ§
            if self.system_monitor:
                self.logger.info("åœæ­¢ç³»ç»Ÿç›‘æ§...")
                self.system_monitor.stop_monitoring()

            # æ¸…ç†çŸ¥è¯†åº“ï¼ˆä¿å­˜æœ€ç»ˆæ•°æ®ï¼‰
            self.logger.info("ä¿å­˜çŸ¥è¯†åº“æ•°æ®...")
            self.knowledge_base.cleanup()

            self.logger.info("âœ… çŸ¥è¯†å¤„ç†å™¨å·²å®‰å…¨å…³é—­")

        except Exception as e:
            self.logger.error(f"âŒ çŸ¥è¯†å¤„ç†å™¨å…³é—­å¤±è´¥: {str(e)}")
            # ç¡®ä¿å³ä½¿å‡ºç°å¼‚å¸¸ï¼ŒçŸ¥è¯†åº“æ•°æ®ä¹Ÿèƒ½ä¿å­˜
            try:
                self.knowledge_base.cleanup()
                self.logger.info("ç´§æ€¥ä¿å­˜çŸ¥è¯†åº“æ•°æ®å®Œæˆ")
            except Exception as cleanup_e:
                self.logger.error(f"ç´§æ€¥ä¿å­˜ä¹Ÿå¤±è´¥: {str(cleanup_e)}")


# å…¨å±€çŸ¥è¯†å¤„ç†å™¨å®ä¾‹
_knowledge_processor: Optional[KnowledgeProcessor] = None
_processor_lock = threading.Lock()


def get_knowledge_processor(enable_auto_qa_extraction: bool = True, enable_auto_compaction: bool = True, enable_system_monitoring: bool = True, enable_auto_cleanup: bool = True, cleanup_dry_run: bool = False) -> KnowledgeProcessor:
    """
    è·å–å…¨å±€çŸ¥è¯†å¤„ç†å™¨å®ä¾‹

    Args:
        enable_auto_qa_extraction: æ˜¯å¦å¯ç”¨è‡ªåŠ¨é—®ç­”å¯¹æŠ½å–
        enable_auto_compaction: æ˜¯å¦å¯ç”¨è‡ªåŠ¨å‹ç¼©
        enable_system_monitoring: æ˜¯å¦å¯ç”¨ç³»ç»Ÿç›‘æ§
        enable_auto_cleanup: æ˜¯å¦å¯ç”¨è‡ªåŠ¨æ¸…ç†ä¸­é—´æ–‡ä»¶
        cleanup_dry_run: æ˜¯å¦ä¸ºæ¸…ç†å¹²è¿è¡Œæ¨¡å¼

    Returns:
        KnowledgeProcessor: çŸ¥è¯†å¤„ç†å™¨å®ä¾‹
    """
    global _knowledge_processor

    if _knowledge_processor is None:
        with _processor_lock:
            if _knowledge_processor is None:
                _knowledge_processor = KnowledgeProcessor(
                    enable_auto_qa_extraction=enable_auto_qa_extraction,
                    enable_auto_compaction=enable_auto_compaction,
                    enable_system_monitoring=enable_system_monitoring,
                    enable_auto_cleanup=enable_auto_cleanup,
                    cleanup_dry_run=cleanup_dry_run
                )

    return _knowledge_processor


def cleanup_knowledge_processor():
    """æ¸…ç†å…¨å±€çŸ¥è¯†å¤„ç†å™¨å®ä¾‹"""
    global _knowledge_processor

    if _knowledge_processor is not None:
        _knowledge_processor.shutdown()
        _knowledge_processor = None

    # æ¸…ç†å…¨å±€ç›‘æ§å™¨
    cleanup_system_monitor()